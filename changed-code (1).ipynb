{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f89c20cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T11:55:56.426271Z",
     "iopub.status.busy": "2024-05-04T11:55:56.425926Z",
     "iopub.status.idle": "2024-05-04T11:55:56.430609Z",
     "shell.execute_reply": "2024-05-04T11:55:56.429778Z"
    },
    "papermill": {
     "duration": 0.018261,
     "end_time": "2024-05-04T11:55:56.432627",
     "exception": false,
     "start_time": "2024-05-04T11:55:56.414366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# credits:\n",
    "# https://www.kaggle.com/code/olyatsimboy/aimo-openmath-mistral-baseline\n",
    "# https://www.kaggle.com/code/aatiffraz/prompt-prediction-w-mixtral-mistral7b-gemma-llama\n",
    "# https://www.kaggle.com/code/thedrcat/aimo-mixtral-baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df82fa6b",
   "metadata": {
    "papermill": {
     "duration": 0.00931,
     "end_time": "2024-05-04T11:55:56.451680",
     "exception": false,
     "start_time": "2024-05-04T11:55:56.442370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Zero-shot MMOS-DeepSeekMath-7B with self-consistency and generated code reasoning evaluation\n",
    "\n",
    "Self-consistency is a modification of the standard greedy decoding in reasoning pipelines via sampling several diverse answers followed by aggregation, e.g., most common answer ([SC-CoT paper](https://arxiv.org/pdf/2203.11171.pdf)).\n",
    "\n",
    "In this kernel, we will consider MMOS-DeepSeekMath-7B RL-tuned backbone; in my experiments, this model produces more consistent code reasoning and the code block execution will allow us to decrease arithmetic hallucinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ddb9d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T11:55:56.472250Z",
     "iopub.status.busy": "2024-05-04T11:55:56.471607Z",
     "iopub.status.idle": "2024-05-04T11:56:32.977718Z",
     "shell.execute_reply": "2024-05-04T11:56:32.976557Z"
    },
    "papermill": {
     "duration": 36.518899,
     "end_time": "2024-05-04T11:56:32.980078",
     "exception": false,
     "start_time": "2024-05-04T11:55:56.461179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c24f74f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T11:18:09.875341Z",
     "iopub.status.busy": "2024-05-04T11:18:09.875018Z",
     "iopub.status.idle": "2024-05-04T11:21:47.363805Z",
     "shell.execute_reply": "2024-05-04T11:21:47.362869Z",
     "shell.execute_reply.started": "2024-05-04T11:18:09.875314Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2024-05-04T11:56:32.990120",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, \n",
    "    AutoTokenizer, \n",
    "    BitsAndBytesConfig, \n",
    "    AutoConfig,\n",
    "    set_seed\n",
    ")\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "MODEL_PATH = \"/kaggle/input/deepseek-math\"\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "config = AutoConfig.from_pretrained(MODEL_PATH)\n",
    "config.gradient_checkpointing = True\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "#     quantization_config=quantization_config,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87796b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T11:21:47.365810Z",
     "iopub.status.busy": "2024-05-04T11:21:47.365159Z",
     "iopub.status.idle": "2024-05-04T11:21:47.372904Z",
     "shell.execute_reply": "2024-05-04T11:21:47.372070Z",
     "shell.execute_reply.started": "2024-05-04T11:21:47.365776Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc553817",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5533ade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T11:17:32.215303Z",
     "iopub.status.busy": "2024-05-04T11:17:32.214933Z",
     "iopub.status.idle": "2024-05-04T11:17:33.210631Z",
     "shell.execute_reply": "2024-05-04T11:17:33.209484Z",
     "shell.execute_reply.started": "2024-05-04T11:17:32.215272Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f8360",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T11:21:47.374335Z",
     "iopub.status.busy": "2024-05-04T11:21:47.374006Z",
     "iopub.status.idle": "2024-05-04T11:21:47.406966Z",
     "shell.execute_reply": "2024-05-04T11:21:47.406044Z",
     "shell.execute_reply.started": "2024-05-04T11:21:47.374305Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/competitions/ai-mathematical-olympiad-prize/data\n",
    "\n",
    "# Load the training data\n",
    "train_data = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/train.csv')\n",
    "\n",
    "# Load the test data\n",
    "test_data = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/test.csv')\n",
    "\n",
    "# Now you can view the first few rows of each to confirm they're loaded correctly\n",
    "olympiad_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d86aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T11:21:47.408546Z",
     "iopub.status.busy": "2024-05-04T11:21:47.408274Z",
     "iopub.status.idle": "2024-05-04T11:21:47.427388Z",
     "shell.execute_reply": "2024-05-04T11:21:47.426309Z",
     "shell.execute_reply.started": "2024-05-04T11:21:47.408524Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clean data\n",
    "olympiad_data.dropna()\n",
    "#View \n",
    "olympiad_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1172f2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T11:21:47.428938Z",
     "iopub.status.busy": "2024-05-04T11:21:47.428661Z",
     "iopub.status.idle": "2024-05-04T11:21:47.524404Z",
     "shell.execute_reply": "2024-05-04T11:21:47.523566Z",
     "shell.execute_reply.started": "2024-05-04T11:21:47.428914Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# No need to do regex\n",
    "aime_data = pd.read_csv('/kaggle/input/aime-problem-set-1983-2024/AIME_Dataset_1983_2024.csv')\n",
    "#Fix structure of columns\n",
    "# rm Year, Problem Number, Part\n",
    "aime_data = aime_data.drop(['Year', 'Problem Number', 'Part'], axis=1)\n",
    "aime_data.dropna()\n",
    "#rename Question: question, Answer:answer, ID:id\n",
    "aime_data.rename(columns={'ID': 'id','Question': 'problem', 'Answer': 'answer'}, inplace=True)\n",
    "#View\n",
    "aime_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d4db1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T11:51:05.894316Z",
     "iopub.status.busy": "2024-05-04T11:51:05.893968Z",
     "iopub.status.idle": "2024-05-04T11:51:06.264174Z",
     "shell.execute_reply": "2024-05-04T11:51:06.262838Z",
     "shell.execute_reply.started": "2024-05-04T11:51:05.894290Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean this\n",
    "amio_data = pd.read_csv('/kaggle/input/amio-parsed-art-of-problem-solving-website/parsed_ArtOfProblemSolving.csv')\n",
    "amio_data.head()\n",
    "\n",
    "patt_to_remove = ['AHSME', 'AJHSME', 'USOMO', 'USAMO', 'USAJMO', 'USOJMO']\n",
    "\n",
    "# Create a boolean mask where True indicates that a row should be deleted\n",
    "mask = amio_data['link'].str.contains('|'.join(patt_to_remove))\n",
    "\n",
    "# Invert the mask to keep rows that do not contain any of the patterns\n",
    "amio_data = amio_data[~mask]\n",
    "\n",
    "# Now, 'amio_24_data' contains only the rows where 'link' doesn't include the specified patterns\n",
    "unique_links = amio_data['link'].unique()\n",
    "print(unique_links)\n",
    "#Fix structure of columns\n",
    "#rm link, letter\n",
    "amio_data = amio_data.drop(['link', 'letter'], axis=1)\n",
    "#change problem_id to id\n",
    "amio_data.rename(columns={'problem_id': 'id'}, inplace=True)\n",
    "#drop na\n",
    "amio_data.dropna()\n",
    "#View\n",
    "amio_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8226ffc0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-04T11:21:48.627379Z",
     "iopub.status.idle": "2024-05-04T11:21:48.627727Z",
     "shell.execute_reply": "2024-05-04T11:21:48.627570Z",
     "shell.execute_reply.started": "2024-05-04T11:21:48.627557Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_data = pd.concat([olympiad_data, aime_data, amio_data, amio_24_data], ignore_index=True)\n",
    "print(f'Length beofre cleaning: {len(combined_data)}')\n",
    "# Prioritize the rows that have 'solution' filled out \n",
    "combined_data_sorted = combined_data.sort_values(by='solution', ascending=False, na_position='last')\n",
    "# Drop duplicates\n",
    "df = combined_data_sorted.drop_duplicates(subset=['problem'], keep='first')\n",
    "print(f'Length after cleaning: {len(df)}')\n",
    "\n",
    "# Boolean indexing to filter rows where 'solution' column is not empty\n",
    "non_empty_solution_rows = df[df['solution'].notnull()]\n",
    "print(f\"Length of those with a 'solution' value: {len(non_empty_solution_rows)}\")\n",
    "\n",
    "# Boolean indexing to filter rows where 'solution' column is empty\n",
    "empty_solution_rows = df[df['solution'].isnull()]\n",
    "\n",
    "# Display the length after cleaning\n",
    "print(f\"Length of those with no 'solution' value: {len(empty_solution_rows)}\")\n",
    "\n",
    "# Now 'empty_solution_rows' contains only rows where 'solution' column is empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d760db1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PRIVATE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd07dd0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-04T11:21:48.628686Z",
     "iopub.status.idle": "2024-05-04T11:21:48.629069Z",
     "shell.execute_reply": "2024-05-04T11:21:48.628888Z",
     "shell.execute_reply.started": "2024-05-04T11:21:48.628873Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6421f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not PRIVATE:\n",
    "    df['answer'] = 0\n",
    "    iter_test = []\n",
    "    for i in range(len(df)):\n",
    "        p = pd.DataFrame(data={'id':[df['id'][i]],'problem':[df['problem'][i]]},index=[0])\n",
    "        a = pd.DataFrame(data={'id':[df['id'][i]],'answer':[df['answer'][i]]},index=[0])\n",
    "        iter_test.append((p,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c4dd8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-04T11:21:48.631677Z",
     "iopub.status.idle": "2024-05-04T11:21:48.632019Z",
     "shell.execute_reply": "2024-05-04T11:21:48.631871Z",
     "shell.execute_reply.started": "2024-05-04T11:21:48.631857Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a04480",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-04T11:21:48.633081Z",
     "iopub.status.idle": "2024-05-04T11:21:48.633531Z",
     "shell.execute_reply": "2024-05-04T11:21:48.633347Z",
     "shell.execute_reply.started": "2024-05-04T11:21:48.633325Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def naive_parse(answer):\n",
    "    out = []\n",
    "    start = False\n",
    "    end = False\n",
    "    for l in reversed(list(answer)):\n",
    "        if l in '0123456789' and not end:\n",
    "            start = True\n",
    "            out.append(l)\n",
    "        else:\n",
    "            if start:\n",
    "                end = True\n",
    "        \n",
    "    out = reversed(out)\n",
    "    return ''.join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc537c4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-04T11:21:48.635326Z",
     "iopub.status.idle": "2024-05-04T11:21:48.635669Z",
     "shell.execute_reply": "2024-05-04T11:21:48.635521Z",
     "shell.execute_reply.started": "2024-05-04T11:21:48.635507Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype='auto',\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca5796",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-04T11:21:48.636670Z",
     "iopub.status.idle": "2024-05-04T11:21:48.636989Z",
     "shell.execute_reply": "2024-05-04T11:21:48.636845Z",
     "shell.execute_reply.started": "2024-05-04T11:21:48.636832Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Transformers Version: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c70967",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-04T11:21:48.638446Z",
     "iopub.status.idle": "2024-05-04T11:21:48.638769Z",
     "shell.execute_reply": "2024-05-04T11:21:48.638623Z",
     "shell.execute_reply.started": "2024-05-04T11:21:48.638609Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677cb598",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-04T11:21:48.640495Z",
     "iopub.status.idle": "2024-05-04T11:21:48.641882Z",
     "shell.execute_reply": "2024-05-04T11:21:48.641647Z",
     "shell.execute_reply.started": "2024-05-04T11:21:48.641622Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_code(text):\n",
    "    if text.startswith(\"```python\"):\n",
    "        text = \"hey\\n\" + text\n",
    "    blocks = [block.split(\"```\", 1)[0].strip() for block in text.split(\"```python\") if '```' in block]\n",
    "    blocks = [block for block in blocks if block]\n",
    "    if not blocks:\n",
    "        return \"\"\n",
    "    code = []\n",
    "    for block in blocks[:-1]:\n",
    "        for line in block.split(\"\\n\"):\n",
    "            if line.startswith(\"    \") or line.startswith(\"import\") or line.startswith(\"def \"):\n",
    "                code.append(line)\n",
    "            elif 'print(' not in line:\n",
    "                code.append(line)\n",
    "    code = \"\\n\".join(code) + \"\\n\" + blocks[-1]\n",
    "    return code.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7074a58a",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.status.busy": "2024-05-04T11:21:48.642785Z",
     "iopub.status.idle": "2024-05-04T11:21:48.643299Z",
     "shell.execute_reply": "2024-05-04T11:21:48.643136Z",
     "shell.execute_reply.started": "2024-05-04T11:21:48.643116Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def process_output(output):\n",
    "    result = output\n",
    "    print(output)\n",
    "    try:\n",
    "        code = extract_code(output)\n",
    "        def repl(match):\n",
    "            if \"real\" not in match.group():\n",
    "                return \"{}{}\".format(match.group()[:-1], ', real=True)')\n",
    "            else:\n",
    "                return \"{}{}\".format(match.group()[:-1], ')')\n",
    "        code = re.sub(r\"symbols\\([^)]+\\)\", repl, code)\n",
    "\n",
    "        code = code.replace('\\n', '\\n    ')\n",
    "            # Add a try...except block\n",
    "        code = \"\\ntry:\\n    from sympy import *\\n    {}\\nexcept Exception as e:\\n    print(e)\\n    print('FAIL')\\n\".format(code)\n",
    "\n",
    "        with open('code.py', 'w') as fout:\n",
    "            fout.write(code)\n",
    "\n",
    "        batcmd = 'timeout 10 ' + sys.executable + ' code.py'\n",
    "        try:\n",
    "            shell_output = subprocess.check_output(batcmd, shell=True).decode('utf8')\n",
    "            print(shell_output)\n",
    "            code_output = round(float(eval(shell_output))) % 1000\n",
    "        except Exception as ee:\n",
    "            print('Run failed ',ee)\n",
    "#             print(code)\n",
    "            code_output = -1\n",
    "\n",
    "        print('CODE RESULTS', code_output)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('ERROR PARSING')\n",
    "        code_output = -1\n",
    "    \n",
    "    try:\n",
    "        result_output = re.findall(r'\\\\boxed\\{(.*)\\}', result)\n",
    "\n",
    "        print('BOXED', result_output)\n",
    "        if not len(result_output):\n",
    "            result_output = naive_parse(result)\n",
    "        else:\n",
    "            result_output = result_output[-1]\n",
    "\n",
    "        print('BOXED', result_output)\n",
    "        if not len(result_output):\n",
    "            result_output = -1\n",
    "        \n",
    "        else:\n",
    "            result_output = round(float(eval(result_output))) % 1000\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('ERROR PARSING')\n",
    "        result_output = -1\n",
    "    \n",
    "    return result_output, code_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb92697",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-04T11:21:48.644513Z",
     "iopub.status.idle": "2024-05-04T11:21:48.644831Z",
     "shell.execute_reply": "2024-05-04T11:21:48.644690Z",
     "shell.execute_reply.started": "2024-05-04T11:21:48.644676Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# tool_instruction = \"The problem is written in LaTeX format where it uses Established mathematical notation and sometimes Fractional part notation.\"\n",
    "# tool_instruction = \" The answer should be given as a non-negative modulo 1000.\"\n",
    "# tool_instruction += '\\nPlease integrate natural language reasoning with programs to solve the problem above, and put your final answer within \\\\boxed{}.'\n",
    "# tool_instruction += \"If the problem includes combinatorial enumeration,  m^0  represents the number of ways to choose zero objects from a set of m objects. therefore m^0 = 1 for all integers m (including 0)\"\n",
    "\n",
    "code_instruction = \"Below is a math problem you are to solve (positive numerical answer):\\n\\\"\"\n",
    "code_instruction2 = \"\"\"To accomplish this, first determine a sympy-based approach for solving the problem by listing each step to take and what functions need to be called in each step. Be clear so even an idiot can follow your instructions, and remember, your final answer should be positive integer, not an algebraic expression!\n",
    "Write the entire script covering all the steps (use comments and document it well) and print the result. After solving the problem, output the final numerical answer within \\\\boxed{}.\n",
    "\n",
    "                        Approach:\"\"\"\n",
    "n_repetitions = 8 if PRIVATE else 2\n",
    "\n",
    "total_results = []\n",
    "total_answers = []\n",
    "\n",
    "for test, submission in iter_test:\n",
    "    problem = test['problem'][0]\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": code_instruction + problem + code_instruction2 \n",
    "             #problem + tool_instruction \n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    query_prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    answers = []\n",
    "    \n",
    "    for _ in tqdm(range(n_repetitions)):\n",
    "        try:\n",
    "            raw_output = pipeline(\n",
    "                query_prompt, \n",
    "                max_new_tokens=2048, \n",
    "                do_sample=True, \n",
    "                temperature=0.8964,\n",
    "                return_full_text=False\n",
    "            )\n",
    "            raw_output = raw_output[0]['generated_text']\n",
    "#             print(raw_output)\n",
    "            result_output, code_output = process_output(raw_output)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            result_output, code_output = -1, -1\n",
    "        \n",
    "        results.append(result_output)\n",
    "        answers.append(code_output)\n",
    "    \n",
    "    combined = results + answers\n",
    "    while -1 in combined:\n",
    "        combined.remove(-1)\n",
    "    if combined:\n",
    "        pred = Counter(combined).most_common(2)\n",
    "        ans = pred[0][0] if not pred[0][0] < 0 or len(pred) < 2 else pred[1][0]\n",
    "    else:\n",
    "        ans = -1\n",
    "    submission['answer'] = ans\n",
    "    if PRIVATE:\n",
    "        env.predict(submission)\n",
    "    \n",
    "    total_results.append(results)\n",
    "    total_answers.append(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c98bbc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "final_answers = []\n",
    "\n",
    "for a, b in zip(total_answers, total_results):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    a[a < 0] = b[a < 0]\n",
    "    \n",
    "    pred = Counter(a.tolist()).most_common(2)\n",
    "\n",
    "    ans = pred[0][0] if not pred[0][0] < 0 or len(pred) < 2 else pred[1][0]\n",
    "\n",
    "    final_answers.append(ans)\n",
    "    print(ans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5948aea",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df[['id','answer']].to_csv(\"submission.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936dd826",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not PRIVATE:\n",
    "    df = pd.read_csv('/kaggle/input/ai-mathematical-olympiad-prize/train.csv')\n",
    "    df['model_answer'] = final_answers\n",
    "    df['match'] = df.answer == df.model_answer\n",
    "    print(f'{df.match.sum()} matches in {len(df)} examples')\n",
    "    df.answer"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8365361,
     "sourceId": 73231,
     "sourceType": "competition"
    },
    {
     "datasetId": 4281572,
     "sourceId": 7369493,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4717118,
     "sourceId": 8008788,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4720595,
     "sourceId": 8012825,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4728129,
     "sourceId": 8023365,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4777425,
     "sourceId": 8091844,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4798051,
     "sourceId": 8120232,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 174126983,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 3900,
     "sourceId": 5112,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 4761,
     "sourceId": 5994,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 8318,
     "sourceId": 11382,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 8332,
     "sourceId": 11394,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-04T11:55:53.669653",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "21267b653022419eb6fc3f47aa4db8ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_926e7ccdad6440be85c76931860b744c",
       "placeholder": "​",
       "style": "IPY_MODEL_feef8334edb24f6da22e8bb1d8d80c67",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "2144e851698b4707ad1c7fc29fe21b03": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3963993becfa487c9ff725f211915e67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f7a725e1b0cc4ad78a62beab5f663065",
       "placeholder": "​",
       "style": "IPY_MODEL_fdb32baaed7145d8a8024b615ef242ca",
       "value": " 19/19 [10:48&lt;00:00, 33.24s/it]"
      }
     },
     "5882b6e860be4a0db012a64fc0704a3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_21267b653022419eb6fc3f47aa4db8ed",
        "IPY_MODEL_d91eb83d016a4381828192a98f798f9b",
        "IPY_MODEL_3963993becfa487c9ff725f211915e67"
       ],
       "layout": "IPY_MODEL_6a892a5561f742bb9db9f13859c18e90"
      }
     },
     "6a892a5561f742bb9db9f13859c18e90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "926e7ccdad6440be85c76931860b744c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d91eb83d016a4381828192a98f798f9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2144e851698b4707ad1c7fc29fe21b03",
       "max": 19,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e0693b32889c42b18b9a3844e045d048",
       "value": 19
      }
     },
     "e0693b32889c42b18b9a3844e045d048": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f7a725e1b0cc4ad78a62beab5f663065": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fdb32baaed7145d8a8024b615ef242ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "feef8334edb24f6da22e8bb1d8d80c67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}