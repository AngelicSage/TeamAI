{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":73231,"databundleVersionId":8365361,"sourceType":"competition"},{"sourceId":7855833,"sourceType":"datasetVersion","datasetId":4605286},{"sourceId":8091844,"sourceType":"datasetVersion","datasetId":4777425},{"sourceId":8095292,"sourceType":"datasetVersion","datasetId":4779706},{"sourceId":175603288,"sourceType":"kernelVersion"},{"sourceId":175716525,"sourceType":"kernelVersion"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":724.728315,"end_time":"2024-02-29T09:37:08.760349","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-02-29T09:25:04.032034","version":"2.5.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"21267b653022419eb6fc3f47aa4db8ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_926e7ccdad6440be85c76931860b744c","placeholder":"​","style":"IPY_MODEL_feef8334edb24f6da22e8bb1d8d80c67","value":"Loading checkpoint shards: 100%"}},"2144e851698b4707ad1c7fc29fe21b03":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3963993becfa487c9ff725f211915e67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7a725e1b0cc4ad78a62beab5f663065","placeholder":"​","style":"IPY_MODEL_fdb32baaed7145d8a8024b615ef242ca","value":" 19/19 [10:48&lt;00:00, 33.24s/it]"}},"5882b6e860be4a0db012a64fc0704a3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_21267b653022419eb6fc3f47aa4db8ed","IPY_MODEL_d91eb83d016a4381828192a98f798f9b","IPY_MODEL_3963993becfa487c9ff725f211915e67"],"layout":"IPY_MODEL_6a892a5561f742bb9db9f13859c18e90"}},"6a892a5561f742bb9db9f13859c18e90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"926e7ccdad6440be85c76931860b744c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d91eb83d016a4381828192a98f798f9b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2144e851698b4707ad1c7fc29fe21b03","max":19,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e0693b32889c42b18b9a3844e045d048","value":19}},"e0693b32889c42b18b9a3844e045d048":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f7a725e1b0cc4ad78a62beab5f663065":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdb32baaed7145d8a8024b615ef242ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"feef8334edb24f6da22e8bb1d8d80c67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load model","metadata":{}},{"cell_type":"code","source":"!pip install /kaggle/input/bitsandbytez/accelerate-0.28.0-py3-none-any.whl\n!pip install /kaggle/input/bitsandbytez/bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl\n!pip install peft\n!pip install git+https://github.com/jiaweizzhao/GaLore","metadata":{"papermill":{"duration":18.075198,"end_time":"2024-02-29T09:25:25.295954","exception":false,"start_time":"2024-02-29T09:25:07.220756","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-07T13:23:10.980805Z","iopub.execute_input":"2024-05-07T13:23:10.981420Z","iopub.status.idle":"2024-05-07T13:24:13.220964Z","shell.execute_reply.started":"2024-05-07T13:23:10.981386Z","shell.execute_reply":"2024-05-07T13:24:13.219819Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/bitsandbytez/accelerate-0.28.0-py3-none-any.whl\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0) (6.0.1)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0) (2.1.2)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0) (0.22.2)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.28.0) (0.4.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.28.0) (3.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.28.0) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.28.0) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.28.0) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.28.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.28.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.28.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.28.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.28.0) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.28.0) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.29.3\n    Uninstalling accelerate-0.29.3:\n      Successfully uninstalled accelerate-0.29.3\nSuccessfully installed accelerate-0.28.0\nProcessing /kaggle/input/bitsandbytez/bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.43.0) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.43.0) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes==0.43.0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes==0.43.0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes==0.43.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes==0.43.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes==0.43.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->bitsandbytes==0.43.0) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->bitsandbytes==0.43.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->bitsandbytes==0.43.0) (1.3.0)\nInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.43.0\nCollecting peft\n  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (6.0.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.39.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft) (4.66.1)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.28.0)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.4.3)\nRequirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft) (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\nDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.10.0\nCollecting git+https://github.com/jiaweizzhao/GaLore\n  Cloning https://github.com/jiaweizzhao/GaLore to /tmp/pip-req-build-rk_pvr8e\n  Running command git clone --filter=blob:none --quiet https://github.com/jiaweizzhao/GaLore /tmp/pip-req-build-rk_pvr8e\n  Resolved https://github.com/jiaweizzhao/GaLore to commit 1b36c33782bdd74a4d6a4f51bc626ef67f51011f\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from galore-torch==1.0) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from galore-torch==1.0) (4.39.3)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (from galore-torch==1.0) (0.43.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes->galore-torch==1.0) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->galore-torch==1.0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->galore-torch==1.0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->galore-torch==1.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->galore-torch==1.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->galore-torch==1.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->galore-torch==1.0) (2024.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (0.22.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (4.66.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers->galore-torch==1.0) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->galore-torch==1.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->galore-torch==1.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->galore-torch==1.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->galore-torch==1.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->galore-torch==1.0) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->galore-torch==1.0) (1.3.0)\nBuilding wheels for collected packages: galore-torch\n  Building wheel for galore-torch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for galore-torch: filename=galore_torch-1.0-py3-none-any.whl size=13310 sha256=c0e4cec7cc05c9146b5f8c4107e69fd3485d10ba2c6e07592c06c76a373dc553\n  Stored in directory: /tmp/pip-ephem-wheel-cache-edd94tq7/wheels/88/47/b5/ca5f75e9f8a2eef76440b7070f8e82f0099831c3d13ebbe221\nSuccessfully built galore-torch\nInstalling collected packages: galore-torch\nSuccessfully installed galore-torch-1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom transformers import (\n    AutoModelForCausalLM, \n    AutoTokenizer, \n    AutoConfig,\n    set_seed\n)\n\nset_seed(42)\nMODEL_PATH = \"/kaggle/input/gemma-2b-it\"\nconfig = AutoConfig.from_pretrained(MODEL_PATH)\nconfig.gradient_checkpointing = True\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, padding_side=\"right\")\n\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_PATH,\n    device_map=\"auto\",\n    torch_dtype=\"auto\",\n    trust_remote_code=True,\n    config=config\n)","metadata":{"papermill":{"duration":664.688061,"end_time":"2024-02-29T09:36:29.988515","exception":false,"start_time":"2024-02-29T09:25:25.300454","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-07T13:24:13.223412Z","iopub.execute_input":"2024-05-07T13:24:13.223842Z","iopub.status.idle":"2024-05-07T13:25:00.205301Z","shell.execute_reply.started":"2024-05-07T13:24:13.223805Z","shell.execute_reply":"2024-05-07T13:25:00.204411Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-05-07 13:24:22.226439: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-07 13:24:22.226560: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-07 13:24:22.386535: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Load Datasets","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:00.207068Z","iopub.execute_input":"2024-05-07T13:25:00.207728Z","iopub.status.idle":"2024-05-07T13:25:00.212059Z","shell.execute_reply.started":"2024-05-07T13:25:00.207694Z","shell.execute_reply":"2024-05-07T13:25:00.211147Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# clean this\namio_data = pd.read_csv('/kaggle/input/amio-parsed-art-of-problem-solving-website/parsed_ArtOfProblemSolving.csv', index_col=False)\namio_data.head()\n\npatt_to_remove = ['AHSME', 'AJHSME', 'USOMO', 'USAMO', 'USAJMO', 'USOJMO']\n\n# Create a boolean mask where True indicates that a row should be deleted\nmask = amio_data['link'].str.contains('|'.join(patt_to_remove))\n\n# Invert the mask to keep rows that do not contain any of the patterns\namio_data = amio_data[~mask]\n\n# Now, 'amio_24_data' contains only the rows where 'link' doesn't include the specified patterns\nunique_links = amio_data['link'].unique()\nprint(unique_links)\n#Fix structure of columns\n#rm link, letter\namio_data = amio_data.drop(['link', 'letter'], axis=1)\n#change problem_id to id\namio_data.rename(columns={'problem_id': 'id'}, inplace=True)\n#drop na\namio_data.dropna()\n#View\namio_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:00.214145Z","iopub.execute_input":"2024-05-07T13:25:00.214668Z","iopub.status.idle":"2024-05-07T13:25:00.537408Z","shell.execute_reply.started":"2024-05-07T13:25:00.214641Z","shell.execute_reply":"2024-05-07T13:25:00.536387Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"['https://artofproblemsolving.com/wiki/index.php/2024_AMC_8_Problems/Problem_1'\n 'https://artofproblemsolving.com/wiki/index.php/2024_AMC_8_Problems/Problem_2'\n 'https://artofproblemsolving.com/wiki/index.php/2024_AMC_8_Problems/Problem_3'\n ...\n 'https://artofproblemsolving.com/wiki/index.php/1983_AIME_Problems/Problem_13'\n 'https://artofproblemsolving.com/wiki/index.php/1983_AIME_Problems/Problem_14'\n 'https://artofproblemsolving.com/wiki/index.php/1983_AIME_Problems/Problem_15']\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                 id  \\\n0  4ba30954e5f3ca72748b3e145f45b705   \n1  4ba30954e5f3ca72748b3e145f45b705   \n2  4ba30954e5f3ca72748b3e145f45b705   \n3  4ba30954e5f3ca72748b3e145f45b705   \n4  085955dda8dfb374689b3f216b54d785   \n\n                                             problem  \\\n0  What is the ones digit of \\[222,222-22,222-2,2...   \n1  What is the ones digit of \\[222,222-22,222-2,2...   \n2  What is the ones digit of \\[222,222-22,222-2,2...   \n3  What is the ones digit of \\[222,222-22,222-2,2...   \n4  What is the value of this expression in decima...   \n\n                                            solution answer  \n0  We can rewrite the expression as \\[222,222-(22...      2  \n1  222,222-22,222 = 200,000\\n200,000 - 2,222 = 19...      2  \n2  We only care about the unit's digits.\\nThus, $...      2  \n3  We just take the units digit of each and subtr...      2  \n4  We see that $\\frac{44}{11}$ is $4$ $\\frac{110}...   6.54  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>problem</th>\n      <th>solution</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4ba30954e5f3ca72748b3e145f45b705</td>\n      <td>What is the ones digit of \\[222,222-22,222-2,2...</td>\n      <td>We can rewrite the expression as \\[222,222-(22...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4ba30954e5f3ca72748b3e145f45b705</td>\n      <td>What is the ones digit of \\[222,222-22,222-2,2...</td>\n      <td>222,222-22,222 = 200,000\\n200,000 - 2,222 = 19...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4ba30954e5f3ca72748b3e145f45b705</td>\n      <td>What is the ones digit of \\[222,222-22,222-2,2...</td>\n      <td>We only care about the unit's digits.\\nThus, $...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4ba30954e5f3ca72748b3e145f45b705</td>\n      <td>What is the ones digit of \\[222,222-22,222-2,2...</td>\n      <td>We just take the units digit of each and subtr...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>085955dda8dfb374689b3f216b54d785</td>\n      <td>What is the value of this expression in decima...</td>\n      <td>We see that $\\frac{44}{11}$ is $4$ $\\frac{110}...</td>\n      <td>6.54</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"combined_data = amio_data\nprint(f'Length before cleaning: {len(combined_data)}')\n# Prioritize the rows that have 'solution' filled out \ncombined_data_sorted = combined_data.sort_values(by='solution', ascending=False, na_position='last')\n# Drop duplicates\ndf = combined_data_sorted.drop_duplicates(subset=['problem'], keep='first')\nprint(f'Length after cleaning{len(df)}')","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:00.538849Z","iopub.execute_input":"2024-05-07T13:25:00.539215Z","iopub.status.idle":"2024-05-07T13:25:00.564935Z","shell.execute_reply.started":"2024-05-07T13:25:00.539189Z","shell.execute_reply":"2024-05-07T13:25:00.563794Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Length before cleaning: 7879\nLength after cleaning2656\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install datasets","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:00.566217Z","iopub.execute_input":"2024-05-07T13:25:00.566570Z","iopub.status.idle":"2024-05-07T13:25:13.562458Z","shell.execute_reply.started":"2024-05-07T13:25:00.566540Z","shell.execute_reply":"2024-05-07T13:25:13.561214Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import Dataset\nf = Dataset.from_pandas(df)\nds = f.train_test_split(test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:13.564065Z","iopub.execute_input":"2024-05-07T13:25:13.564369Z","iopub.status.idle":"2024-05-07T13:25:14.183914Z","shell.execute_reply.started":"2024-05-07T13:25:13.564342Z","shell.execute_reply":"2024-05-07T13:25:14.183005Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ds = ds.filter(lambda x: max([len(x[\"problem\"]),len(x[\"solution\"])])<=720)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:14.185356Z","iopub.execute_input":"2024-05-07T13:25:14.185901Z","iopub.status.idle":"2024-05-07T13:25:14.341469Z","shell.execute_reply.started":"2024-05-07T13:25:14.185875Z","shell.execute_reply":"2024-05-07T13:25:14.340594Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/2124 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bf73edc969a34fc1a082d2dde179afe9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/532 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6176633e64f94e5fbb7f131e8a1c6c8b"}},"metadata":{}}]},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:14.342761Z","iopub.execute_input":"2024-05-07T13:25:14.343070Z","iopub.status.idle":"2024-05-07T13:25:14.349207Z","shell.execute_reply.started":"2024-05-07T13:25:14.343045Z","shell.execute_reply":"2024-05-07T13:25:14.348307Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'problem', 'solution', 'answer', '__index_level_0__'],\n        num_rows: 1246\n    })\n    test: Dataset({\n        features: ['id', 'problem', 'solution', 'answer', '__index_level_0__'],\n        num_rows: 320\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tokenize","metadata":{}},{"cell_type":"code","source":"batch_size=6","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:14.354082Z","iopub.execute_input":"2024-05-07T13:25:14.354360Z","iopub.status.idle":"2024-05-07T13:25:14.359663Z","shell.execute_reply.started":"2024-05-07T13:25:14.354337Z","shell.execute_reply":"2024-05-07T13:25:14.358680Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(example):\n    return tokenizer(text=example[\"problem\"], text_target=example[\"solution\"], padding=\"max_length\",max_length=400)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:14.361006Z","iopub.execute_input":"2024-05-07T13:25:14.361862Z","iopub.status.idle":"2024-05-07T13:25:14.370228Z","shell.execute_reply.started":"2024-05-07T13:25:14.361829Z","shell.execute_reply":"2024-05-07T13:25:14.369387Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\nds = ds.map(tokenize_function, batched=True, remove_columns=ds[\"train\"].column_names)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:14.371447Z","iopub.execute_input":"2024-05-07T13:25:14.371713Z","iopub.status.idle":"2024-05-07T13:25:16.787559Z","shell.execute_reply.started":"2024-05-07T13:25:14.371690Z","shell.execute_reply":"2024-05-07T13:25:16.786741Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1246 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64f8afcf38eb4e3c857f95b50aa151e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/320 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95cabedff94946bc81c949d226627dcf"}},"metadata":{}}]},{"cell_type":"code","source":"max([len(ds[\"train\"][\"input_ids\"][i]) for i in range(len(ds))])","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:16.788556Z","iopub.execute_input":"2024-05-07T13:25:16.788865Z","iopub.status.idle":"2024-05-07T13:25:17.494693Z","shell.execute_reply.started":"2024-05-07T13:25:16.788840Z","shell.execute_reply":"2024-05-07T13:25:17.493798Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"400"},"metadata":{}}]},{"cell_type":"code","source":"max([len(ds[\"train\"][\"labels\"][i]) for i in range(len(ds))])","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:17.496072Z","iopub.execute_input":"2024-05-07T13:25:17.496893Z","iopub.status.idle":"2024-05-07T13:25:18.188952Z","shell.execute_reply.started":"2024-05-07T13:25:17.496854Z","shell.execute_reply":"2024-05-07T13:25:18.187810Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"400"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrain_dataloader = DataLoader(\n    ds[\"train\"], shuffle=True, collate_fn=data_collator, batch_size=batch_size, pin_memory=True\n)\neval_dataloader = DataLoader(ds[\"test\"], collate_fn=data_collator, batch_size=batch_size, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:18.190261Z","iopub.execute_input":"2024-05-07T13:25:18.190613Z","iopub.status.idle":"2024-05-07T13:25:18.196741Z","shell.execute_reply.started":"2024-05-07T13:25:18.190581Z","shell.execute_reply":"2024-05-07T13:25:18.195825Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Define hyperparameter","metadata":{}},{"cell_type":"code","source":"lr = 1e-5\nnum_epochs = 1\nnum_training_steps = num_epochs * len(train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:18.197941Z","iopub.execute_input":"2024-05-07T13:25:18.198307Z","iopub.status.idle":"2024-05-07T13:25:18.209711Z","shell.execute_reply.started":"2024-05-07T13:25:18.198276Z","shell.execute_reply":"2024-05-07T13:25:18.208616Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Fine-tuned gemma-2b","metadata":{}},{"cell_type":"code","source":"from tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:18.210834Z","iopub.execute_input":"2024-05-07T13:25:18.211163Z","iopub.status.idle":"2024-05-07T13:25:18.224850Z","shell.execute_reply.started":"2024-05-07T13:25:18.211140Z","shell.execute_reply":"2024-05-07T13:25:18.223927Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"import gc\ndevice = 'cuda'","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:18.226037Z","iopub.execute_input":"2024-05-07T13:25:18.226374Z","iopub.status.idle":"2024-05-07T13:25:18.237686Z","shell.execute_reply.started":"2024-05-07T13:25:18.226343Z","shell.execute_reply":"2024-05-07T13:25:18.237006Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"!pip install /kaggle/input/galore-torch/galore_torch-1.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:18.238798Z","iopub.execute_input":"2024-05-07T13:25:18.239089Z","iopub.status.idle":"2024-05-07T13:25:31.420678Z","shell.execute_reply.started":"2024-05-07T13:25:18.239063Z","shell.execute_reply":"2024-05-07T13:25:31.419561Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Processing /kaggle/input/galore-torch/galore_torch-1.0-py3-none-any.whl\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from galore-torch==1.0) (2.1.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from galore-torch==1.0) (4.39.3)\nRequirement already satisfied: bitsandbytes in /opt/conda/lib/python3.10/site-packages (from galore-torch==1.0) (0.43.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes->galore-torch==1.0) (1.26.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->galore-torch==1.0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->galore-torch==1.0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->galore-torch==1.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->galore-torch==1.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->galore-torch==1.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->galore-torch==1.0) (2024.2.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (0.22.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->galore-torch==1.0) (4.66.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers->galore-torch==1.0) (3.1.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->galore-torch==1.0) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->galore-torch==1.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->galore-torch==1.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->galore-torch==1.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->galore-torch==1.0) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->galore-torch==1.0) (1.3.0)\ngalore-torch is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import LoraConfig","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:31.422146Z","iopub.execute_input":"2024-05-07T13:25:31.422466Z","iopub.status.idle":"2024-05-07T13:25:31.474032Z","shell.execute_reply.started":"2024-05-07T13:25:31.422438Z","shell.execute_reply":"2024-05-07T13:25:31.473296Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"lora_config = LoraConfig(\n    bias=\"none\",\n    target_modules=\"all-linear\",\n    init_lora_weights=True,\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:31.475219Z","iopub.execute_input":"2024-05-07T13:25:31.475519Z","iopub.status.idle":"2024-05-07T13:25:31.480117Z","shell.execute_reply.started":"2024-05-07T13:25:31.475496Z","shell.execute_reply":"2024-05-07T13:25:31.478992Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model.add_adapter(lora_config)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:31.481268Z","iopub.execute_input":"2024-05-07T13:25:31.481554Z","iopub.status.idle":"2024-05-07T13:25:31.812559Z","shell.execute_reply.started":"2024-05-07T13:25:31.481531Z","shell.execute_reply":"2024-05-07T13:25:31.811527Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from galore_torch import GaLoreAdamW8bit\n# define param groups as galore_params and non_galore_params\noptimizer = GaLoreAdamW8bit(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:31.813771Z","iopub.execute_input":"2024-05-07T13:25:31.814073Z","iopub.status.idle":"2024-05-07T13:25:31.851684Z","shell.execute_reply.started":"2024-05-07T13:25:31.814048Z","shell.execute_reply":"2024-05-07T13:25:31.850683Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from transformers import get_scheduler\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:31.852993Z","iopub.execute_input":"2024-05-07T13:25:31.853296Z","iopub.status.idle":"2024-05-07T13:25:31.864186Z","shell.execute_reply.started":"2024-05-07T13:25:31.853272Z","shell.execute_reply":"2024-05-07T13:25:31.863246Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from accelerate import Accelerator\naccelerater = Accelerator()\naccelerater.prepare(\n    train_dataloader, eval_dataloader, model, optimizer\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:31.865424Z","iopub.execute_input":"2024-05-07T13:25:31.865882Z","iopub.status.idle":"2024-05-07T13:25:31.893947Z","shell.execute_reply.started":"2024-05-07T13:25:31.865855Z","shell.execute_reply":"2024-05-07T13:25:31.893020Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(<accelerate.data_loader.DataLoaderShard at 0x790c922d6470>,\n <accelerate.data_loader.DataLoaderShard at 0x790c922d7490>,\n GemmaForCausalLM(\n   (model): GemmaModel(\n     (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n     (layers): ModuleList(\n       (0-17): 18 x GemmaDecoderLayer(\n         (self_attn): GemmaSdpaAttention(\n           (q_proj): lora.Linear4bit(\n             (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n             (lora_dropout): ModuleDict(\n               (default): Identity()\n             )\n             (lora_A): ModuleDict(\n               (default): Linear(in_features=2048, out_features=8, bias=False)\n             )\n             (lora_B): ModuleDict(\n               (default): Linear(in_features=8, out_features=2048, bias=False)\n             )\n             (lora_embedding_A): ParameterDict()\n             (lora_embedding_B): ParameterDict()\n           )\n           (k_proj): lora.Linear4bit(\n             (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n             (lora_dropout): ModuleDict(\n               (default): Identity()\n             )\n             (lora_A): ModuleDict(\n               (default): Linear(in_features=2048, out_features=8, bias=False)\n             )\n             (lora_B): ModuleDict(\n               (default): Linear(in_features=8, out_features=256, bias=False)\n             )\n             (lora_embedding_A): ParameterDict()\n             (lora_embedding_B): ParameterDict()\n           )\n           (v_proj): lora.Linear4bit(\n             (base_layer): Linear4bit(in_features=2048, out_features=256, bias=False)\n             (lora_dropout): ModuleDict(\n               (default): Identity()\n             )\n             (lora_A): ModuleDict(\n               (default): Linear(in_features=2048, out_features=8, bias=False)\n             )\n             (lora_B): ModuleDict(\n               (default): Linear(in_features=8, out_features=256, bias=False)\n             )\n             (lora_embedding_A): ParameterDict()\n             (lora_embedding_B): ParameterDict()\n           )\n           (o_proj): lora.Linear4bit(\n             (base_layer): Linear4bit(in_features=2048, out_features=2048, bias=False)\n             (lora_dropout): ModuleDict(\n               (default): Identity()\n             )\n             (lora_A): ModuleDict(\n               (default): Linear(in_features=2048, out_features=8, bias=False)\n             )\n             (lora_B): ModuleDict(\n               (default): Linear(in_features=8, out_features=2048, bias=False)\n             )\n             (lora_embedding_A): ParameterDict()\n             (lora_embedding_B): ParameterDict()\n           )\n           (rotary_emb): GemmaRotaryEmbedding()\n         )\n         (mlp): GemmaMLP(\n           (gate_proj): lora.Linear4bit(\n             (base_layer): Linear4bit(in_features=2048, out_features=16384, bias=False)\n             (lora_dropout): ModuleDict(\n               (default): Identity()\n             )\n             (lora_A): ModuleDict(\n               (default): Linear(in_features=2048, out_features=8, bias=False)\n             )\n             (lora_B): ModuleDict(\n               (default): Linear(in_features=8, out_features=16384, bias=False)\n             )\n             (lora_embedding_A): ParameterDict()\n             (lora_embedding_B): ParameterDict()\n           )\n           (up_proj): lora.Linear4bit(\n             (base_layer): Linear4bit(in_features=2048, out_features=16384, bias=False)\n             (lora_dropout): ModuleDict(\n               (default): Identity()\n             )\n             (lora_A): ModuleDict(\n               (default): Linear(in_features=2048, out_features=8, bias=False)\n             )\n             (lora_B): ModuleDict(\n               (default): Linear(in_features=8, out_features=16384, bias=False)\n             )\n             (lora_embedding_A): ParameterDict()\n             (lora_embedding_B): ParameterDict()\n           )\n           (down_proj): lora.Linear4bit(\n             (base_layer): Linear4bit(in_features=16384, out_features=2048, bias=False)\n             (lora_dropout): ModuleDict(\n               (default): Identity()\n             )\n             (lora_A): ModuleDict(\n               (default): Linear(in_features=16384, out_features=8, bias=False)\n             )\n             (lora_B): ModuleDict(\n               (default): Linear(in_features=8, out_features=2048, bias=False)\n             )\n             (lora_embedding_A): ParameterDict()\n             (lora_embedding_B): ParameterDict()\n           )\n           (act_fn): PytorchGELUTanh()\n         )\n         (input_layernorm): GemmaRMSNorm()\n         (post_attention_layernorm): GemmaRMSNorm()\n       )\n     )\n     (norm): GemmaRMSNorm()\n   )\n   (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n ),\n AcceleratedOptimizer (\n Parameter Group 0\n     betas: (0.9, 0.999)\n     eps: 1e-08\n     initial_lr: 1e-05\n     lr: 1e-05\n     weight_decay: 0.01\n ))"},"metadata":{}}]},{"cell_type":"code","source":"progress_bar = tqdm(range(num_training_steps))\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        outputs = model(**batch)\n        loss = outputs.loss\n        accelerater.backward(loss)\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T13:25:31.895235Z","iopub.execute_input":"2024-05-07T13:25:31.895574Z","iopub.status.idle":"2024-05-07T14:07:55.756422Z","shell.execute_reply.started":"2024-05-07T13:25:31.895549Z","shell.execute_reply":"2024-05-07T14:07:55.755432Z"},"trusted":true},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/208 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4b184cb47ff4faca35e81801d3d6175"}},"metadata":{}}]},{"cell_type":"code","source":"model.save_pretrained(\"/kaggle/working/\")","metadata":{"execution":{"iopub.status.busy":"2024-05-07T14:07:55.758141Z","iopub.execute_input":"2024-05-07T14:07:55.758502Z","iopub.status.idle":"2024-05-07T14:07:56.720594Z","shell.execute_reply.started":"2024-05-07T14:07:55.758469Z","shell.execute_reply":"2024-05-07T14:07:56.719560Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/integrations/peft.py:391: FutureWarning: The `active_adapter` method is deprecated and will be removed in a future version.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /kaggle/input/gemma-2b-it - will assume that the vocabulary was not modified.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"import transformers\n\npipeline = transformers.pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype='auto',\n    device_map=\"auto\",\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nfrom collections import defaultdict\n\n\ntool_instruction = \" The answer should be given as a non-negative modulo 1000.\"\ntool_instruction += '\\nPlease integrate natural language reasoning with programs to solve the problem above, and put your final answer within \\\\boxed{}.'\n\n\nn_repetitions = 1\ntemperature = 0.8964\n\ntotal_results = []\ntotal_answers = []\n\n\nfor i in tqdm(range(len(df))):\n    id_ = df['id'].loc[i]\n    problem = df['problem'].loc[i]\n\n    messages = [\n        {\n            \"role\": \"user\", \n            \"content\": problem + tool_instruction\n        }\n    ]\n    \n    query_prompt = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False\n    )\n    \n    results = []\n    answers = []\n     \n    \n    for _ in tqdm(range(n_repetitions)):\n        try:\n            raw_output = pipeline(\n                query_prompt, \n                max_new_tokens=2048, \n                do_sample=True, \n                temperature=temperature,\n                return_full_text=False\n            )\n            raw_output = raw_output[0]['generated_text']\n\n            result_output, code_output = process_output(raw_output)\n\n            torch.cuda.empty_cache()\n            gc.collect()\n\n        except Exception as e:\n            print(e)\n            result_output, code_output = -1, -1\n        \n        results.append(result_output)\n        answers.append(code_output)\n    \n    total_results.append(results)\n    total_answers.append(answers)","metadata":{"papermill":{"duration":34.259365,"end_time":"2024-02-29T09:37:05.548829","exception":false,"start_time":"2024-02-29T09:36:31.289464","status":"completed"},"tags":[],"_kg_hide-output":true,"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom collections import Counter\n\ndf['leng'] = df['problem'].astype(str).map(len)\ndf['orig_index'] = df.index.values\ndf = df.sort_values(by=['leng', 'id']).reset_index(drop=True)\ndf['enumerates'] = range(0, len(df))\ndf = df.sort_values('orig_index').reset_index(drop=True)\n\nenumerate_i = 0\nfinal_answers = []\nfor a, b in zip(total_answers, total_results):\n    a = np.array(a)\n    b = np.array(b)\n    a[a < 0] = b[a < 0]\n    pred = Counter(a.tolist()).most_common(2)\n    pred = pred + [(-1,0)]\n    val_previously, freq_previously = pred[0]\n    for val, freq in pred[1:]: \n        if freq == freq_previously:\n            val_previously = min(val_previously,val )\n    enumerates = df.enumerates.values[enumerate_i]\n    ans = val_previously if not val_previously < 0 else pred[1][0]\n    enumerate_i+= 1    \n    final_answers.append(ans)\n    print(ans)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['answer'] = final_answers","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['id','answer']].to_csv(\"submission.csv\", header=True, index=False)","metadata":{"papermill":{"duration":0.021128,"end_time":"2024-02-29T09:37:05.574782","exception":false,"start_time":"2024-02-29T09:37:05.553654","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}